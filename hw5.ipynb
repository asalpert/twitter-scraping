{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hw 5: Sentiment Analysis on Twitter Data 🐦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "Collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For this homework, work through **Lab 5 (Sentiment Analysis on Movie Reviews)** first. Most of the things we ask you to do in this homework are explained in the lab. In general, you should feel free to import any package that we have previously used in class. Ensure that all plots have the necessary components that a plot should have (e.g. axes labels, a title, and a legend if it is applicable).\n",
    "\n",
    "Frequently **save** your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators and Sources\n",
    "Furthermore, in addition to recording your **collaborators** on this homework, please also remember to **cite/indicate all external sources** used when finishing this assignment. \n",
    "> This includes peers, TAs, and links to online sources. \n",
    "\n",
    "Note that these citations will be taken into account during the grading and regrading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collaborators and sources:\n",
    "# Albert Einstein and Marie Curie\n",
    "# https://developers.google.com/edu/python/strings\n",
    "\n",
    "# your code here\n",
    "answer = 'my answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Do not change the number of cells!** Your submission notebook should have exactly one code cell per problem. \n",
    "* Do **not** remove the `# your code here` line and add you solution after that line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "import sys\n",
    "import re, string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Usage\n",
    "\n",
    "APIs, or \"application programming interface,\" are tools and routines used to build software applications. For example, Twitter uses an API to allow different programs and projects to access different aspects of Twitter. With some APIs, one would be able to post to Twitter, or perhaps search for different tweets (which will be used within this homework). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public and Secret Keys\n",
    "\n",
    "This Twitter API, along with many others, utilizes public and secret keys to make sure that only validated individuals can access the API commands and functions. Plugging these into the program can validate the user and allow the API to know who is using which commands. For the most part, these APIs (or companies) make it pretty easy to receive their own API keys to be used for a number of processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Accessing API Keys\n",
    "\n",
    "To create your own API Keys for Twitter Data, the steps are quite simple! While this does require a Twitter account, there is no extra information or payment necessary to access this data.\n",
    "\n",
    "First, go to https://developer.twitter.com and sign in to your account. If you do not have a Twitter account (or don't want to link your personal account), you can use a separate email for this.\n",
    "\n",
    "Next, click on Apps and fill out the forms to the best of your ability (not all information is necessary and where applicable, note that this is for a university course/academic use). This will require a phone number, which Twitter uses as a safety check (they don't hand out API keys to just everyone!).\n",
    "\n",
    "Once approved, click on Keys and Tokens, and you should find your API Keys and access tokens!\n",
    "\n",
    "**PLEASE READ:** If you are not approved within a timely manner, you may use someone else's (approved) account's key and access token. Please do not wait until the last day to do this!!! Give yourself ample time to finish the assignment. Alternatively, you can contact us via Piazza and we can provide a zipped `sampleTwitterData` folder for you to work with. This is only to be used in an emergency case. In this **pre-scraped** data, there are 10 CSV files containting the tweets for 10 keywords and each CSV has over 500 tweets, but these tweets are **not** processed! You will still need to implement and run an appropriate version of `preProcess()` (under problem 1) on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.1\n",
    "\n",
    "**Do this!** Create a variable `api` and assign it the result of the `twitter.Api` function with the appropriate arguments. Ignore any arguments that are not realted to your consumer information or access tokens. Enable `sleep_on_rate_limit`.  \n",
    "\n",
    "> **Hint**: Use the `?` character IPython's tool to explore documentation to find our what arguemnts are needed. **Note:** Make sure to remove this before you submit your assignment, it will break your grader and **we will not be able to give you credit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2. Get and Preprocess the Twitter Data\n",
    "\n",
    "Let's start by adding in your Twitter API keys, which can be found from the Twitter developer website. This will give us access for searching tweets, but mostly **limiting us to the past week** and occasionally restricting the amount of tweets we can pull at a time.\n",
    "\n",
    "Your next few tasks are to implement the following three functions that will pull and clean the information from Twitter. The last task will be conducting a sentiment analysis on the data that has been pulled! As a fair warning, Twitter data can be pretty messy; your results may not be nearly as clean as the movie dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 2.1 \n",
    "\n",
    "**Do this!** Complete the following function that will take an arbitrary search term and return a list of tweet words.\n",
    "\n",
    "**PLEASE BE CAREFUL ABOUT INFINITE LOOPS DURING THIS ASSIGNMENT! IF YOU MAKE TOO MANY REQUESTS TO THE API, YOU CAN GET RATE LIMITED, WHICH CAN BAN YOU FROM USING IT FOR A PERIOD OF TIME**\n",
    "\n",
    "> **Hint**: Make sure it works before you continue. Look at the returned list, its length, and _some_ of its entries. **Best Practice**: Do not print out the entire list in the version of the notebook that you submit/deploy/share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getResults(searchTerm, untilID):\n",
    "    \n",
    "    # This fuction will return a list of tweets.\n",
    "    # We will use api.GetSearch() in order to pull the Twitter data\n",
    "    #\n",
    "    # There are several parameters that we will need to include:\n",
    "    #\n",
    "    #     term: string, the term that is being searched\n",
    "    #     since: string in format 'YYYY-MM-DD' which will serve as the earliest date\n",
    "    #     until: string in format 'YYYY-MM-DD' which will serve as the latest data \n",
    "    #     count: int, the number of tweets to return, max of 100\n",
    "    #     result_type: string, type of sorting for tweets. Typically 'recent'\n",
    "    #     max_id: int, another check to limit the tweets returned. Typically sys.maxsize\n",
    "    #     lang: string, indication of the language being used. We recommend leaving lang as 'en'.\n",
    "    #\n",
    "    # You are free to change these however you wish.\n",
    "    #\n",
    "    # CAUTION: The 'since' variable must be at most a week prior to the current date!\n",
    "    #          If you would like to search further, you must apply through Twitter\n",
    "    \n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_search_term = \"data science\" # Replace this with your chosen search term! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = getResults(my_search_term, sys.maxsize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2\n",
    "\n",
    "Now, we will need to process the tweets. \n",
    "\n",
    "**Do this!** Complete the following function that processes _one_ tweet. The function takes in a Twitter object from python-twitter representing one tweet and return the processed result! \n",
    "* Make sure to not consider _retweets_ (`result.retweeted_status`) or a _media posts_ (`result.media`).\n",
    "    * If a `result` is one of those, return `None`. \n",
    "* Often there are links at the end of the tweet. Remove those by keep anything before `\"https://\"`.\n",
    "* Remove whitespaces and newlines (`\\n`).\n",
    "* Deal with punctuation within the tweets: Remove most (if not all) punctuation.\n",
    "* Convert everything to all lowercase. \n",
    "* Split the result into a list of words. \n",
    "\n",
    "Return this list of words as `processedResult`.\n",
    "\n",
    "> **Hint**: You may use _regular expressions_ for this probelm. Regular expressions are extremely useful when performing string parsing or string searching. `re` is the Python package for this. \n",
    "\n",
    "*Note: this question has hidden tests, or is graded on style of code and not just answer alone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preProcess(result):\n",
    "    \n",
    "    ...\n",
    "        \n",
    "    return processedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test this you might need to rerun this a couple of times \n",
    "# until you hit a tweet that is not a media post or retweet.\n",
    "preProcess(results[np.random.randint(0,100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3\n",
    "\n",
    "Now, let's put it all togehter. Since we will ilkely end up with less than 100 tweets, once we preprocess all of them, we have to put the `getResults` call into a `while` loop. \n",
    "\n",
    "**Do this!** Complete the following fucntion that will take in a search term and run through the twitter API to find the most recent tweets using that search term!\n",
    "\n",
    "* Create a `while` loop that runs as long as the length of `processedResults` is under `100`. In the while loop:\n",
    "    * Call the `getResults` function, passing in the `searchTerm` as well as `untilID`.\n",
    "    * Create a loop going through each `result` in the list of returned results from `getResults`. In that loop:\n",
    "        * Run `preProcess` on each `result`: if the returned value is not `None`, append the returned list of words and the `result.id` to their respective lists.\n",
    "        * Make sure to break the inner loop once you have 100 processed results.\n",
    "* **WARNING**: Twitter api implements **rate limiting** and it is pretty strict. The api to scrape the Twitter data will run slowly after multiple trials and you will have to wait 15-30 minutes before being able to run again! So, please think carefully about your implmentation below, especially avoid implementing an infinite loop ☠️!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def searchTerm(searchTerm):\n",
    "    \n",
    "    # These two variables are used to keep track of calls made to the API\n",
    "    untilID = sys.maxsize\n",
    "    ids = []\n",
    "    processedResults = []\n",
    "    \n",
    "    # # Use this as a template!\n",
    "    #\n",
    "    # while ...:\n",
    "    #      **Your code here**\n",
    "    #\n",
    "    #      untilID = min(ids) - 1        # Be sure to include this!\n",
    "    # \n",
    "    # return processedResults\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return processedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select your search term to test the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = searchTerm(my_search_term) # feel free to go change this above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Hint**: Make sure this works before you continue. Look at the returned data, its type, length, and _some_ of its entries. **Best Practice**: Do not print out the entire data in the version of the notebook that you submit/deploy/share. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. Analyzing Twitter Data\n",
    "\n",
    "Great! We now have all the data stored in our `data` variable. We can cycle through this data set and perform the same rule-based sentiment analysis that we saw previously in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "**Write up!** Let's create a hypothesis about the content of our tweets.\n",
    "* What would you guess the fraction of tweets with positive and negative emotions will be for your data/search term?\n",
    "* Write this up (_before_ you perform the sentiment analysis) in the form of a **hypothesis (Q1)**.\n",
    "\n",
    "\n",
    "We will investigate how accurate this hypothesis was at the end of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 3.2\n",
    "\n",
    "**Do this!** Complete the following function that runs a rule-based sentiment analysis on _one_ given entry.\n",
    "* Set the score to zero, then loop through each word in the entry\n",
    "    * At each word, add one to the score if it is in `positive_words`, \n",
    "    * subtract one if it is in `negative_words`\n",
    "    * or do nothing if it is in neither!\n",
    "* Return `1` if the score is not negative and `-1` otherwise. \n",
    "\n",
    "\n",
    " > **Hint**: We will declare `positive_words` and `negative_words` as`global` variables, so don't bother about passing those in as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyzeSentiment(entry):\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run all out tweets trhough this function and collect their sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "\n",
    "global negative_words\n",
    "global positive_words\n",
    "\n",
    "with open('utility/data/negative-words.txt') as f:\n",
    "    negative_words = [word.strip() for word in f.readlines() if word[0] not in [';', '\\n']]\n",
    "\n",
    "with open('utility/data/positive-words.txt') as f:\n",
    "    positive_words = [word.strip() for word in f.readlines() if word[0] not in [';', '\\n']]\n",
    "    \n",
    "for entry in data:\n",
    "    sentiments.append(analyzeSentiment(entry))\n",
    "sentiment_labels = np.array(sentiments)    \n",
    "    \n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Visualizing the Results\n",
    "\n",
    "The final step is creating a few simple charts to look at the overall sentiment of the current Twitter search.\n",
    "\n",
    "### Problem 4.1\n",
    "\n",
    "**Do this!** Create a `bar` chart that visualizes the frequency of the positive and negative tweets in your dataset. Use appropriate axis labels, and include the search term (remember that you stored that in a variable earlier on) in your figure title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's run a configuration to make prettier plots\n",
    "plt.rcdefaults()\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 4.2\n",
    "\n",
    "**Write up!** Let's compare these results with our hypothesis **(Q1)**.\n",
    "* How accurate was your hypothesis?\n",
    "* What do you think could have caused your guess being very accurate or inaccurate? \n",
    "\n",
    "We will see another way of looking at this data to find more explanations in the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Another Visualization: Wordclouds\n",
    "\n",
    "For a slightly more colorful view at the overall data, we can use a wordcloud module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(data2plot):\n",
    "    \n",
    "    overallWords = ' '\n",
    "\n",
    "    for entry in data2plot:\n",
    "        for word in entry:\n",
    "            overallWords += word + ' '\n",
    "\n",
    "    return overallWords\n",
    "\n",
    "wordcloud = WordCloud(width=600, height=430, max_words=50).generate(get_all_words(data))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at wordclouds based on the sentiment! To do this, we split up the data into one list of lists of all positive tweets and one for all negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = [i for indx,i in enumerate(data) if sentiments[indx] == 1]\n",
    "\n",
    "negative_data = [i for indx,i in enumerate(data) if sentiments[indx] == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 4.3\n",
    "\n",
    "**Do this!** Create one wordcloud for the postive tweets and one for the negative tweets, that _intuitivley_ visualizes your results. \n",
    "* Use a different `colormap` for each wordcloud (check out the availbale colormaps [here](https://matplotlib.org/stable/tutorials/colors/colormaps.html)) **and/or** \n",
    "* play with the `background_color` (check out the available colors [here](https://matplotlib.org/stable/gallery/color/named_colors.html)).\n",
    "* Add appropriate titles to your subplots. \n",
    "\n",
    "> **Hint**: Follow the example above and use `get_all_words()`.\n",
    "\n",
    "> **[🐍 Python Feature 🐍]**: We can create figures with **multiple plots** using `plt.subplot`. The first number indicates the number of rows, the second input is the number of columns and the third is the plot you want to fill next. Like if you want to plot into the lower right corner of a figure with four plots in a 2x2 grid, then you would use `plt.subplot(224)` \n",
    "\n",
    "*Note: this question is graded on style/design choices of your visualization and not just on correctness alone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "...\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Summarize your Findings\n",
    "\n",
    "### Problem 5.1\n",
    "\n",
    "**Write up!** The visualizations reveal a lot of information about your Twitter data. Describe your basic findings by answering the following questions:\n",
    "\n",
    "- What was the overall sentiment? \n",
    "- What were some of the most/least frequent words that were used (larger = more common)? \n",
    "- Why do you think this is? \n",
    "- Do you believe this would be different during different weeks?\n",
    "- How do the words used and their frquency differ for positive versus negative sentiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 5.2\n",
    "\n",
    "**Write up!** Elaborate on one specific thing or insight from your analysis that you find particularly interesing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "otter": {
   "tests": {
    "q2.2": {
     "name": "q2.2",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> class Tweet:\n...     def __init__(self, text, retweeted_status = False, media = False):\n...         self.retweeted_status = retweeted_status\n...         self.media = media\n...         self.text = text\n...         \n>>> retweeted = Tweet(\"blah\", True)\n>>> media = Tweet(\"blah\", False, True)\n>>> t = Tweet(\"This is a tweet, with punctuation.\\nIt also has a link: https://computerscience.com\")\n>>> \n>>> preProcess(retweeted) == None\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> class Tweet:\n...     def __init__(self, text, retweeted_status = False, media = False):\n...         self.retweeted_status = retweeted_status\n...         self.media = media\n...         self.text = text\n...         \n>>> retweeted = Tweet(\"blah\", True)\n>>> media = Tweet(\"blah\", False, True)\n>>> t = Tweet(\"This is a tweet, with punctuation.\\nIt also has a link: https://computerscience.com\")\n>>> \n>>> preProcess(media) == None\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> class Tweet:\n...     def __init__(self, text, retweeted_status = False, media = False):\n...         self.retweeted_status = retweeted_status\n...         self.media = media\n...         self.text = text\n...         \n>>> retweeted = Tweet(\"blah\", True)\n>>> media = Tweet(\"blah\", False, True)\n>>> t = Tweet(\"This is a tweet, with punctuation.\\nIt also has a link: https://computerscience.com\")\n>>> \n>>> preProcess(t) == [\n...                     'this',\n...                      'is',\n...                      'a',\n...                      'tweet',\n...                      'with',\n...                      'punctuation',\n...                      'it',\n...                      'also',\n...                      'has',\n...                      'a',\n...                      'link'\n...                  ]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(data) == 100\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(data[0]) == list\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> data[0] != data[1]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 8,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> analyzeSentiment(['absence']) == -1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> analyzeSentiment(['this', 'is', 'a', 'bad', 'good', 'great', 'sentence']) == 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
